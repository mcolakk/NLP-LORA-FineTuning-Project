{
  "best_global_step": 800,
  "best_metric": 0.9405511021614075,
  "best_model_checkpoint": "/content/drive/MyDrive/LORA_Project_A100_Run/DIVERSE_Model_V4_Custom/checkpoint-800",
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 852,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0706090026478376,
      "grad_norm": 0.4134075343608856,
      "learning_rate": 1.955399061032864e-05,
      "loss": 1.2262,
      "step": 20
    },
    {
      "epoch": 0.1412180052956752,
      "grad_norm": 0.5307415723800659,
      "learning_rate": 1.9084507042253523e-05,
      "loss": 1.1229,
      "step": 40
    },
    {
      "epoch": 0.2118270079435128,
      "grad_norm": 0.4272124767303467,
      "learning_rate": 1.8615023474178405e-05,
      "loss": 1.0244,
      "step": 60
    },
    {
      "epoch": 0.2824360105913504,
      "grad_norm": 0.33166536688804626,
      "learning_rate": 1.8145539906103288e-05,
      "loss": 1.0128,
      "step": 80
    },
    {
      "epoch": 0.353045013239188,
      "grad_norm": 0.24322840571403503,
      "learning_rate": 1.767605633802817e-05,
      "loss": 0.9495,
      "step": 100
    },
    {
      "epoch": 0.353045013239188,
      "eval_loss": 0.9836302399635315,
      "eval_runtime": 17.5974,
      "eval_samples_per_second": 25.629,
      "eval_steps_per_second": 6.421,
      "step": 100
    },
    {
      "epoch": 0.4236540158870256,
      "grad_norm": 0.2662402391433716,
      "learning_rate": 1.7206572769953053e-05,
      "loss": 0.9335,
      "step": 120
    },
    {
      "epoch": 0.4942630185348632,
      "grad_norm": 0.22741597890853882,
      "learning_rate": 1.6737089201877936e-05,
      "loss": 0.8838,
      "step": 140
    },
    {
      "epoch": 0.5648720211827007,
      "grad_norm": 0.26620936393737793,
      "learning_rate": 1.6267605633802818e-05,
      "loss": 0.908,
      "step": 160
    },
    {
      "epoch": 0.6354810238305384,
      "grad_norm": 0.3165626525878906,
      "learning_rate": 1.57981220657277e-05,
      "loss": 0.9118,
      "step": 180
    },
    {
      "epoch": 0.706090026478376,
      "grad_norm": 0.33294278383255005,
      "learning_rate": 1.5328638497652583e-05,
      "loss": 0.9205,
      "step": 200
    },
    {
      "epoch": 0.706090026478376,
      "eval_loss": 0.9584592580795288,
      "eval_runtime": 17.5822,
      "eval_samples_per_second": 25.651,
      "eval_steps_per_second": 6.427,
      "step": 200
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 0.339958518743515,
      "learning_rate": 1.4859154929577466e-05,
      "loss": 0.9156,
      "step": 220
    },
    {
      "epoch": 0.8473080317740512,
      "grad_norm": 0.3068849742412567,
      "learning_rate": 1.4389671361502348e-05,
      "loss": 0.9032,
      "step": 240
    },
    {
      "epoch": 0.9179170344218888,
      "grad_norm": 0.25156494975090027,
      "learning_rate": 1.3920187793427231e-05,
      "loss": 0.8806,
      "step": 260
    },
    {
      "epoch": 0.9885260370697264,
      "grad_norm": 0.3034272789955139,
      "learning_rate": 1.3450704225352114e-05,
      "loss": 0.8819,
      "step": 280
    },
    {
      "epoch": 1.05648720211827,
      "grad_norm": 0.2820461690425873,
      "learning_rate": 1.2981220657276996e-05,
      "loss": 0.8679,
      "step": 300
    },
    {
      "epoch": 1.05648720211827,
      "eval_loss": 0.9512860178947449,
      "eval_runtime": 17.5923,
      "eval_samples_per_second": 25.636,
      "eval_steps_per_second": 6.423,
      "step": 300
    },
    {
      "epoch": 1.1270962047661077,
      "grad_norm": 0.26653093099594116,
      "learning_rate": 1.2511737089201879e-05,
      "loss": 0.8909,
      "step": 320
    },
    {
      "epoch": 1.1977052074139454,
      "grad_norm": 0.27897998690605164,
      "learning_rate": 1.2042253521126761e-05,
      "loss": 0.8974,
      "step": 340
    },
    {
      "epoch": 1.2683142100617828,
      "grad_norm": 0.32421308755874634,
      "learning_rate": 1.1572769953051644e-05,
      "loss": 0.8703,
      "step": 360
    },
    {
      "epoch": 1.3389232127096204,
      "grad_norm": 0.30334189534187317,
      "learning_rate": 1.1103286384976526e-05,
      "loss": 0.8461,
      "step": 380
    },
    {
      "epoch": 1.409532215357458,
      "grad_norm": 0.3347715437412262,
      "learning_rate": 1.0633802816901409e-05,
      "loss": 0.8733,
      "step": 400
    },
    {
      "epoch": 1.409532215357458,
      "eval_loss": 0.9473420977592468,
      "eval_runtime": 17.5646,
      "eval_samples_per_second": 25.677,
      "eval_steps_per_second": 6.433,
      "step": 400
    },
    {
      "epoch": 1.4801412180052957,
      "grad_norm": 0.40093377232551575,
      "learning_rate": 1.0164319248826291e-05,
      "loss": 0.9319,
      "step": 420
    },
    {
      "epoch": 1.5507502206531334,
      "grad_norm": 0.3119821548461914,
      "learning_rate": 9.694835680751174e-06,
      "loss": 0.8904,
      "step": 440
    },
    {
      "epoch": 1.6213592233009708,
      "grad_norm": 0.2934371829032898,
      "learning_rate": 9.225352112676057e-06,
      "loss": 0.8868,
      "step": 460
    },
    {
      "epoch": 1.6919682259488085,
      "grad_norm": 0.29785841703414917,
      "learning_rate": 8.755868544600939e-06,
      "loss": 0.8766,
      "step": 480
    },
    {
      "epoch": 1.7625772285966461,
      "grad_norm": 0.3088121712207794,
      "learning_rate": 8.286384976525822e-06,
      "loss": 0.8961,
      "step": 500
    },
    {
      "epoch": 1.7625772285966461,
      "eval_loss": 0.9440219402313232,
      "eval_runtime": 17.5905,
      "eval_samples_per_second": 25.639,
      "eval_steps_per_second": 6.424,
      "step": 500
    },
    {
      "epoch": 1.8331862312444835,
      "grad_norm": 0.4876495897769928,
      "learning_rate": 7.816901408450704e-06,
      "loss": 0.8885,
      "step": 520
    },
    {
      "epoch": 1.9037952338923212,
      "grad_norm": 0.30562230944633484,
      "learning_rate": 7.347417840375587e-06,
      "loss": 0.8627,
      "step": 540
    },
    {
      "epoch": 1.9744042365401588,
      "grad_norm": 0.33354252576828003,
      "learning_rate": 6.87793427230047e-06,
      "loss": 0.874,
      "step": 560
    },
    {
      "epoch": 2.0423654015887025,
      "grad_norm": 0.3435969352722168,
      "learning_rate": 6.408450704225353e-06,
      "loss": 0.8841,
      "step": 580
    },
    {
      "epoch": 2.11297440423654,
      "grad_norm": 0.32396388053894043,
      "learning_rate": 5.938967136150235e-06,
      "loss": 0.9115,
      "step": 600
    },
    {
      "epoch": 2.11297440423654,
      "eval_loss": 0.9423007369041443,
      "eval_runtime": 17.5807,
      "eval_samples_per_second": 25.653,
      "eval_steps_per_second": 6.428,
      "step": 600
    },
    {
      "epoch": 2.183583406884378,
      "grad_norm": 0.3534196615219116,
      "learning_rate": 5.469483568075118e-06,
      "loss": 0.8818,
      "step": 620
    },
    {
      "epoch": 2.2541924095322154,
      "grad_norm": 0.32709911465644836,
      "learning_rate": 5e-06,
      "loss": 0.836,
      "step": 640
    },
    {
      "epoch": 2.324801412180053,
      "grad_norm": 0.31442850828170776,
      "learning_rate": 4.530516431924883e-06,
      "loss": 0.9023,
      "step": 660
    },
    {
      "epoch": 2.3954104148278907,
      "grad_norm": 0.32367265224456787,
      "learning_rate": 4.0610328638497655e-06,
      "loss": 0.8133,
      "step": 680
    },
    {
      "epoch": 2.466019417475728,
      "grad_norm": 0.48951292037963867,
      "learning_rate": 3.5915492957746485e-06,
      "loss": 0.8448,
      "step": 700
    },
    {
      "epoch": 2.466019417475728,
      "eval_loss": 0.9416318535804749,
      "eval_runtime": 17.5816,
      "eval_samples_per_second": 25.652,
      "eval_steps_per_second": 6.427,
      "step": 700
    },
    {
      "epoch": 2.5366284201235656,
      "grad_norm": 0.3207103908061981,
      "learning_rate": 3.122065727699531e-06,
      "loss": 0.8962,
      "step": 720
    },
    {
      "epoch": 2.6072374227714032,
      "grad_norm": 0.349183052778244,
      "learning_rate": 2.652582159624413e-06,
      "loss": 0.8815,
      "step": 740
    },
    {
      "epoch": 2.677846425419241,
      "grad_norm": 0.369488924741745,
      "learning_rate": 2.1830985915492958e-06,
      "loss": 0.8805,
      "step": 760
    },
    {
      "epoch": 2.7484554280670785,
      "grad_norm": 0.29787296056747437,
      "learning_rate": 1.7136150234741785e-06,
      "loss": 0.8449,
      "step": 780
    },
    {
      "epoch": 2.819064430714916,
      "grad_norm": 0.34379008412361145,
      "learning_rate": 1.244131455399061e-06,
      "loss": 0.842,
      "step": 800
    },
    {
      "epoch": 2.819064430714916,
      "eval_loss": 0.9405511021614075,
      "eval_runtime": 17.5906,
      "eval_samples_per_second": 25.639,
      "eval_steps_per_second": 6.424,
      "step": 800
    },
    {
      "epoch": 2.889673433362754,
      "grad_norm": 0.32513222098350525,
      "learning_rate": 7.746478873239437e-07,
      "loss": 0.8579,
      "step": 820
    },
    {
      "epoch": 2.9602824360105915,
      "grad_norm": 0.3754994869232178,
      "learning_rate": 3.051643192488263e-07,
      "loss": 0.8234,
      "step": 840
    }
  ],
  "logging_steps": 20,
  "max_steps": 852,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1095120932765696e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
