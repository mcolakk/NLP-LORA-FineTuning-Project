# NLP Projesi: LoRA ile LLM Fine-Tuning

Bu proje, **Qwen2.5-Coder-1.5B-Instruct** modelini **Deep** ve **Diverse** veri setleri kullanarak LoRA yÃ¶ntemi ile eÄŸitmek ve kodlama yeteneÄŸini artÄ±rmak amacÄ±yla yapÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“‚ Dosya Ä°Ã§eriÄŸi
- `train.py`: Modelin eÄŸitimi iÃ§in kullanÄ±lan V4 konfigÃ¼rasyonlu kod.
- `eval.py`: Modelleri AtCoder (Easy) benchmark testine sokan kod.
- `requirements.txt`: Gerekli kÃ¼tÃ¼phaneler.
- `*.json`: EÄŸitim sÄ±rasÄ±ndaki Loss deÄŸerlerini iÃ§eren log dosyalarÄ±.

## ğŸ“Š Benchmark SonuÃ§larÄ± (Pass@1)
EÄŸitilen modeller AtCoder platformu sorularÄ± ile test edilmiÅŸtir.

| Model Kategorisi | En Ä°yi Checkpoint | Pass@1 (%) | Ã‡Ã¶zÃ¼len Soru |
| :--- | :--- | :--- | :--- |
| **Deep_instruction** | checkpoint-step-200 | %26.8 | 11/41 |
| **Diverse_instruction** | checkpoint-step-200 | %31.7 | 13/41 |

## ğŸ“ˆ EÄŸitim Grafikleri
DetaylÄ± Loss grafikleri proje raporunda mevcuttur.
<img wi<img width="846" height="547" alt="Unknown" src="https://github.com/user-attachments/assets/20ba7504-1938-472b-a875-432257fbb8d2" />
dth="846" height="547" alt="Unknown-2" src="https://github.com/user-attachments/assets/49af52c8-92d0-4ebd-9814-9b81709cb9f1" />
